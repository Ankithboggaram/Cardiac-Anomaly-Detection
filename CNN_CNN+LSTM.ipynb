{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Copy of RHMS model(shared).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18DVgk5SlIjB",
        "outputId": "22d08658-70f1-4854-92ce-bee0db436882"
      },
      "source": [
        "!pip install --upgrade wfdb\n",
        "!pip install --upgrade xlsxwriter\n",
        "!pip install --upgrade tensorflow_model_optimization\n",
        "!pip install keras-visualizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.7/dist-packages (from wfdb) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.3.4->wfdb) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->wfdb) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (3.0.4)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: keras-visualizer in /usr/local/lib/python3.7/dist-packages (2.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2rltUeil0Ep"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoX9zAUPZHdv"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.layers import Conv1D, Flatten, LSTM, Dense, Dropout, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_model_optimization as tfmot\n",
        "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
        "quant_apply = tfmot.quantization.keras.quantize_apply\n",
        "quantize_scope = tfmot.quantization.keras.quantize_scope\n",
        "\n",
        "\n",
        "LastValueQuantizer = tfmot.quantization.keras.quantizers.LastValueQuantizer\n",
        "MovingAverageQuantizer = tfmot.quantization.keras.quantizers.MovingAverageQuantizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U5CgztDnh48"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/gdrive\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a02o0MvoXxQZ"
      },
      "source": [
        "# !unzip gdrive/MyDrive/mit-bih-arrhythmia-database-1.0.0.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS-ft6lBcP7o"
      },
      "source": [
        "**Loading the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqPZ08BJZxJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d9f1a3-6130-438d-d511-bc1594950653"
      },
      "source": [
        "dataset = {'mitdb': 'ARR', 'nsrdb': 'NSR', 'chfdb': 'CHF'}\n",
        "for db, dir in dataset.items():\n",
        "  wfdb.dl_database(db, os.getcwd()+'/'+dir)\n",
        "  wfdb.dl_files(db, os.getcwd()+'/'+dir, ['RECORDS'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating record list for: 100\n",
            "Generating record list for: 101\n",
            "Generating record list for: 102\n",
            "Generating record list for: 103\n",
            "Generating record list for: 104\n",
            "Generating record list for: 105\n",
            "Generating record list for: 106\n",
            "Generating record list for: 107\n",
            "Generating record list for: 108\n",
            "Generating record list for: 109\n",
            "Generating record list for: 111\n",
            "Generating record list for: 112\n",
            "Generating record list for: 113\n",
            "Generating record list for: 114\n",
            "Generating record list for: 115\n",
            "Generating record list for: 116\n",
            "Generating record list for: 117\n",
            "Generating record list for: 118\n",
            "Generating record list for: 119\n",
            "Generating record list for: 121\n",
            "Generating record list for: 122\n",
            "Generating record list for: 123\n",
            "Generating record list for: 124\n",
            "Generating record list for: 200\n",
            "Generating record list for: 201\n",
            "Generating record list for: 202\n",
            "Generating record list for: 203\n",
            "Generating record list for: 205\n",
            "Generating record list for: 207\n",
            "Generating record list for: 208\n",
            "Generating record list for: 209\n",
            "Generating record list for: 210\n",
            "Generating record list for: 212\n",
            "Generating record list for: 213\n",
            "Generating record list for: 214\n",
            "Generating record list for: 215\n",
            "Generating record list for: 217\n",
            "Generating record list for: 219\n",
            "Generating record list for: 220\n",
            "Generating record list for: 221\n",
            "Generating record list for: 222\n",
            "Generating record list for: 223\n",
            "Generating record list for: 228\n",
            "Generating record list for: 230\n",
            "Generating record list for: 231\n",
            "Generating record list for: 232\n",
            "Generating record list for: 233\n",
            "Generating record list for: 234\n",
            "Generating list of all files for: 100\n",
            "Generating list of all files for: 101\n",
            "Generating list of all files for: 102\n",
            "Generating list of all files for: 103\n",
            "Generating list of all files for: 104\n",
            "Generating list of all files for: 105\n",
            "Generating list of all files for: 106\n",
            "Generating list of all files for: 107\n",
            "Generating list of all files for: 108\n",
            "Generating list of all files for: 109\n",
            "Generating list of all files for: 111\n",
            "Generating list of all files for: 112\n",
            "Generating list of all files for: 113\n",
            "Generating list of all files for: 114\n",
            "Generating list of all files for: 115\n",
            "Generating list of all files for: 116\n",
            "Generating list of all files for: 117\n",
            "Generating list of all files for: 118\n",
            "Generating list of all files for: 119\n",
            "Generating list of all files for: 121\n",
            "Generating list of all files for: 122\n",
            "Generating list of all files for: 123\n",
            "Generating list of all files for: 124\n",
            "Generating list of all files for: 200\n",
            "Generating list of all files for: 201\n",
            "Generating list of all files for: 202\n",
            "Generating list of all files for: 203\n",
            "Generating list of all files for: 205\n",
            "Generating list of all files for: 207\n",
            "Generating list of all files for: 208\n",
            "Generating list of all files for: 209\n",
            "Generating list of all files for: 210\n",
            "Generating list of all files for: 212\n",
            "Generating list of all files for: 213\n",
            "Generating list of all files for: 214\n",
            "Generating list of all files for: 215\n",
            "Generating list of all files for: 217\n",
            "Generating list of all files for: 219\n",
            "Generating list of all files for: 220\n",
            "Generating list of all files for: 221\n",
            "Generating list of all files for: 222\n",
            "Generating list of all files for: 223\n",
            "Generating list of all files for: 228\n",
            "Generating list of all files for: 230\n",
            "Generating list of all files for: 231\n",
            "Generating list of all files for: 232\n",
            "Generating list of all files for: 233\n",
            "Generating list of all files for: 234\n",
            "Created local base download directory: /content/ARR\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Generating record list for: 16265\n",
            "Generating record list for: 16272\n",
            "Generating record list for: 16273\n",
            "Generating record list for: 16420\n",
            "Generating record list for: 16483\n",
            "Generating record list for: 16539\n",
            "Generating record list for: 16773\n",
            "Generating record list for: 16786\n",
            "Generating record list for: 16795\n",
            "Generating record list for: 17052\n",
            "Generating record list for: 17453\n",
            "Generating record list for: 18177\n",
            "Generating record list for: 18184\n",
            "Generating record list for: 19088\n",
            "Generating record list for: 19090\n",
            "Generating record list for: 19093\n",
            "Generating record list for: 19140\n",
            "Generating record list for: 19830\n",
            "Generating list of all files for: 16265\n",
            "Generating list of all files for: 16272\n",
            "Generating list of all files for: 16273\n",
            "Generating list of all files for: 16420\n",
            "Generating list of all files for: 16483\n",
            "Generating list of all files for: 16539\n",
            "Generating list of all files for: 16773\n",
            "Generating list of all files for: 16786\n",
            "Generating list of all files for: 16795\n",
            "Generating list of all files for: 17052\n",
            "Generating list of all files for: 17453\n",
            "Generating list of all files for: 18177\n",
            "Generating list of all files for: 18184\n",
            "Generating list of all files for: 19088\n",
            "Generating list of all files for: 19090\n",
            "Generating list of all files for: 19093\n",
            "Generating list of all files for: 19140\n",
            "Generating list of all files for: 19830\n",
            "Created local base download directory: /content/NSR\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Generating record list for: chf01\n",
            "Generating record list for: chf02\n",
            "Generating record list for: chf03\n",
            "Generating record list for: chf04\n",
            "Generating record list for: chf05\n",
            "Generating record list for: chf06\n",
            "Generating record list for: chf07\n",
            "Generating record list for: chf08\n",
            "Generating record list for: chf09\n",
            "Generating record list for: chf10\n",
            "Generating record list for: chf11\n",
            "Generating record list for: chf12\n",
            "Generating record list for: chf13\n",
            "Generating record list for: chf14\n",
            "Generating record list for: chf15\n",
            "Generating list of all files for: chf01\n",
            "Generating list of all files for: chf02\n",
            "Generating list of all files for: chf03\n",
            "Generating list of all files for: chf04\n",
            "Generating list of all files for: chf05\n",
            "Generating list of all files for: chf06\n",
            "Generating list of all files for: chf07\n",
            "Generating list of all files for: chf08\n",
            "Generating list of all files for: chf09\n",
            "Generating list of all files for: chf10\n",
            "Generating list of all files for: chf11\n",
            "Generating list of all files for: chf12\n",
            "Generating list of all files for: chf13\n",
            "Generating list of all files for: chf14\n",
            "Generating list of all files for: chf15\n",
            "Created local base download directory: /content/CHF\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Downloading files...\n",
            "Finished downloading files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGi5C5WT0ET3"
      },
      "source": [
        "data_path = 'ARR/'\n",
        "records = np.loadtxt(\"ARR/RECORDS\", dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYcmUHxtcOqk"
      },
      "source": [
        "#These are the beat classifications according to physiobank\n",
        "\n",
        "invalid = [ \"[\", \"!\", \"]\", \"x\", \"(\", \")\", \"p\", \"t\", \"u\", \"`\", \"'\", \"^\", \"|\", \"~\", \"+\", \"s\", \"T\", \"*\", \"D\", \"=\", '\"', \"@\" ]\n",
        "\n",
        "abnormal = [ \"L\", \"R\", \"B\", \"A\", \"a\", \"J\", \"S\", \"V\", \"r\", \"F\", \"e\", \"j\", \"n\", \"E\", \"/\", \"f\", \"Q\", \"?\" ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WwTXh7RdHcy"
      },
      "source": [
        "**Processing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZro0z22c9Nf"
      },
      "source": [
        "def classify_beat(symbol):\n",
        "    if symbol in abnormal :\n",
        "        return 1\n",
        "    elif symbol == \"N\" or symbol == \".\":\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt2vpZQ2dbS_"
      },
      "source": [
        "def get_sequence(signal, beat_loc, window_sec, fs):\n",
        "    window_one_side = window_sec * fs\n",
        "    beat_start = beat_loc - window_one_side\n",
        "    beat_end = beat_loc + window_one_side\n",
        "    if beat_end < signal.shape[0]:\n",
        "        sequence = signal[beat_start:beat_end, 0]\n",
        "        return sequence.reshape(1, -1, 1)\n",
        "    else:\n",
        "        return np.array([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LYCMhG-d8Nk"
      },
      "source": [
        "all_sequences = []\n",
        "all_labels = []\n",
        "window_sec = 3\n",
        "subject_map = []\n",
        "for subject in records:\n",
        "    record = wfdb.rdrecord(f'/content/ARR/{subject}')\n",
        "    annotation = wfdb.rdann(f'/content/ARR/{subject}', 'atr')\n",
        "    atr_symbol = annotation.symbol\n",
        "    atr_sample = annotation.sample\n",
        "    fs = record.fs\n",
        "    scaler = StandardScaler()\n",
        "    signal = scaler.fit_transform(record.p_signal)\n",
        "    subject_labels = []\n",
        "    for i, i_sample in enumerate(atr_sample):\n",
        "        label = classify_beat(atr_symbol[i])\n",
        "        sequence = get_sequence(signal, i_sample, window_sec, fs)\n",
        "        if label is not None and sequence.size > 0:\n",
        "            all_sequences.append(sequence)\n",
        "            subject_labels.append(label)\n",
        "\n",
        "    normal_percentage = sum(subject_labels) / len(subject_labels)\n",
        "    subject_map.append({\n",
        "        \"subject\": subject,\n",
        "        \"percentage\": normal_percentage,\n",
        "        \"num_seq\": len(subject_labels),\n",
        "        \"start\": len(all_labels),\n",
        "        \"end\": len(all_labels)+len(subject_labels)\n",
        "    })\n",
        "    all_labels.extend(subject_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D9Kx7O2ez6N"
      },
      "source": [
        "subject_map = pd.DataFrame(subject_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5wfYuGOe1Jc"
      },
      "source": [
        "bins = [0, 0.2, 0.6, 1.0]\n",
        "subject_map[\"bin\"] = pd.cut(subject_map['percentage'], bins=bins, labels=False, include_lowest=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ZaNUY0e9AG"
      },
      "source": [
        "train, validation = train_test_split(subject_map, test_size=0.25, stratify=subject_map[\"bin\"], random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EEH4IitfBgh"
      },
      "source": [
        "def build_dataset(df, all_sequences, all_labels):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i, row in df.iterrows():\n",
        "        start = int(row[\"start\"])\n",
        "        end = int(row[\"end\"])\n",
        "        sequences.extend(all_sequences[start:end])\n",
        "        labels.extend(all_labels[start:end])\n",
        "        \n",
        "    return np.vstack(sequences), np.vstack(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMhIBMjffGja"
      },
      "source": [
        "X_train, y_train = build_dataset(train, all_sequences, all_labels)\n",
        "X_val, y_val = build_dataset(validation, all_sequences, all_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOv7QsEKDmpH"
      },
      "source": [
        "# data = pd.DataFrame(X_val.reshape(X_val.shape[0], X_val.shape[1]))\n",
        "# data['label'] = y_val\n",
        "# data\n",
        "# data.to_csv('/content/gdrive/MyDrive/val.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPgZf-Y3fKvh",
        "outputId": "b6c92c10-15a9-4b38-8331-de03bfec2332"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((82873, 2160, 1), (82873, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1yPQYWSiNj_"
      },
      "source": [
        "#Default Quantization Classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvq7apPdiP-R"
      },
      "source": [
        "class DefaultQuantizeConfigCNN(tfmot.quantization.keras.QuantizeConfig):\n",
        "    # Configure how to quantize weights.\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      return [(layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    # Configure how to quantize activations.\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "      return [(layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
        "      # , in the same order\n",
        "      layer.kernel = quantize_weights[0]\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
        "      # , in the same order.\n",
        "      layer._activation = quantize_activations[0]\n",
        "\n",
        "    # Configure how to quantize outputs (may be equivalent to activations).\n",
        "    def get_output_quantizers(self, layer):\n",
        "      return []\n",
        "\n",
        "    def get_config(self):\n",
        "      return {}\n",
        "class DefaultQuantizeConfigCNNLSTM(tfmot.quantization.keras.QuantizeConfig):\n",
        "    # Configure how to quantize weights.\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      return [(layer.layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    # Configure how to quantize activations.\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "      return [(layer.layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
        "      # , in the same order\n",
        "      layer.kernel = quantize_weights[0]\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
        "      # , in the same order.\n",
        "      layer._activation = quantize_activations[0]\n",
        "\n",
        "    # Configure how to quantize outputs (may be equivalent to activations).\n",
        "    def get_output_quantizers(self, layer):\n",
        "      return []\n",
        "\n",
        "    def get_config(self):\n",
        "      return {}\n",
        "# class DefaultQuantizeFlattenConfigCNNLSTM(tfmot.quantization.keras.QuantizeConfig):\n",
        "#     # Configure how to quantize weights.\n",
        "#     def get_weights_and_quantizers(self, layer):\n",
        "#       return [(layer.layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
        "\n",
        "#     # Configure how to quantize activations.\n",
        "#     def get_activations_and_quantizers(self, layer):\n",
        "#       return [(layer.layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
        "\n",
        "#     def set_quantize_weights(self, layer, quantize_weights):\n",
        "#       # Add this line for each item returned in `get_weights_and_quantizers`\n",
        "#       # , in the same order\n",
        "#       layer.kernel = quantize_weights[0]\n",
        "\n",
        "#     def set_quantize_activations(self, layer, quantize_activations):\n",
        "#       # Add this line for each item returned in `get_activations_and_quantizers`\n",
        "#       # , in the same order.\n",
        "#       layer._activation = quantize_activations[0]\n",
        "\n",
        "#     # Configure how to quantize outputs (may be equivalent to activations).\n",
        "#     def get_output_quantizers(self, layer):\n",
        "#       return []\n",
        "\n",
        "#     def get_config(self):\n",
        "#       return {}\n",
        "class DefaultQuantizeLSTMConfigCNNLSTM(tfmot.quantization.keras.QuantizeConfig):\n",
        "    # Configure how to quantize weights.\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      return [(layer.cell.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    # Configure how to quantize activations.\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "      return [(layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
        "      # , in the same order\n",
        "      layer.kernel = quantize_weights[0]\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
        "      # , in the same order.\n",
        "      layer._activation = quantize_activations[0]\n",
        "\n",
        "    # Configure how to quantize outputs (may be equivalent to activations).\n",
        "    def get_output_quantizers(self, layer):\n",
        "      return []\n",
        "\n",
        "    def get_config(self):\n",
        "      return {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94_tn9PwOjiE"
      },
      "source": [
        "#CNN Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnBNUgeBfM40",
        "outputId": "63c77587-3c16-4ad7-f4f7-9c833c148a2d"
      },
      "source": [
        "sequence_size = X_train.shape[1]\n",
        "n_features = 1\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    quantize_annotate_layer(Conv1D(\n",
        "        filters=8,\n",
        "        kernel_size=4,\n",
        "        strides=1,\n",
        "        input_shape=(sequence_size, n_features),\n",
        "        padding=\"same\",\n",
        "        activation=\"relu\"\n",
        "    ), DefaultQuantizeConfigCNN()),\n",
        "    quantize_annotate_layer(Flatten()),\n",
        "    quantize_annotate_layer(Dropout(0.5)),\n",
        "    quantize_annotate_layer(Dense(\n",
        "        1,\n",
        "        activation=\"sigmoid\",\n",
        "        name=\"output\",\n",
        "    ))\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "# Compiling the model\n",
        "cnn_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "cnn_model.summary()\n",
        "cnn_model.save('cnn_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_annotate_4 (Quantiz (None, 2160, 8)           40        \n",
            "_________________________________________________________________\n",
            "quantize_annotate_5 (Quantiz (None, 17280)             0         \n",
            "_________________________________________________________________\n",
            "quantize_annotate_6 (Quantiz (None, 17280)             0         \n",
            "_________________________________________________________________\n",
            "quantize_annotate_7 (Quantiz (None, 1)                 17281     \n",
            "=================================================================\n",
            "Total params: 17,321\n",
            "Trainable params: 17,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxswfuE_YUCJ"
      },
      "source": [
        "# def get_flopsCNN(model_h5_path):\n",
        "#     session = tf.compat.v1.Session()\n",
        "#     graph = tf.compat.v1.get_default_graph()\n",
        "\n",
        "\n",
        "#     with graph.as_default():\n",
        "#         with session.as_default():\n",
        "#             with quantize_scope({'DefaultQuantizeConfigCNN': DefaultQuantizeConfigCNN}):\n",
        "#               model = tf.keras.models.load_model(model_h5_path)\n",
        "\n",
        "#               run_meta = tf.compat.v1.RunMetadata()\n",
        "#               opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "#               flops = tf.compat.v1.profiler.profile(graph=graph,\n",
        "#                                                     run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "#               return flops.total_float_ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "gSBRwAcdOqTp",
        "outputId": "d3e6e3c0-fb1d-467f-9d83-1ca9edda0925"
      },
      "source": [
        "# print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(cnn_model.layers[0].get_weights()))\n",
        "hist_cnn = cnn_model.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    batch_size=128,\n",
        "    epochs=15,\n",
        "    validation_data=(X_val, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            " 45/648 [=>............................] - ETA: 44s - loss: 0.4201 - accuracy: 0.8151"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-aa77b775ea13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMeDiP9xpexB"
      },
      "source": [
        "# cnn_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
        "with quantize_scope(\n",
        "    {'DefaultQuantizeConfigCNN': DefaultQuantizeConfigCNN}):\n",
        "    cnn_quant_aware = tfmot.quantization.keras.quantize_apply(cnn_model)\n",
        "cnn_quant_aware.summary()\n",
        "cnn_quant_aware.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "cnn_quant_aware.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    batch_size=128,\n",
        "    epochs=15,\n",
        "    validation_data=(X_val, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyAx2Xae2-Ya"
      },
      "source": [
        "#CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Wyvg-tQwKq"
      },
      "source": [
        "sequence_size = X_train.shape[1]\n",
        "n_features = 1 \n",
        "n_subsequences = 4\n",
        "subsequence_size = int(sequence_size / n_subsequences)\n",
        "\n",
        "# Reshaping to be (samples, subsequences, sequence, feature)\n",
        "X_train = X_train.reshape(-1, n_subsequences, subsequence_size, n_features)\n",
        "X_val = X_val.reshape(-1, n_subsequences, subsequence_size, n_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEJlKoQ-VrrK",
        "outputId": "b9f3f263-da4a-48dc-f1c0-225a8ef1d259"
      },
      "source": [
        "cnn_lstm_model = Sequential([\n",
        "    quantize_annotate_layer(TimeDistributed(\n",
        "        Conv1D(\n",
        "            filters=4,\n",
        "            kernel_size=4,\n",
        "            strides=1,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\"\n",
        "        ), \n",
        "        input_shape=(n_subsequences, subsequence_size, n_features)\n",
        "    ), DefaultQuantizeConfigCNNLSTM()),\n",
        "    TimeDistributed(quantize_annotate_layer(Flatten())),\n",
        "    quantize_annotate_layer(LSTM(units=2), DefaultQuantizeLSTMConfigCNNLSTM()),\n",
        "    quantize_annotate_layer(Dense(\n",
        "        1,\n",
        "        activation=\"sigmoid\",\n",
        "        name=\"output\",\n",
        "    ))\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "# Compiling the model\n",
        "cnn_lstm_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "cnn_lstm_model.summary()\n",
        "cnn_lstm_model.save('cnn_lstm_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_annotate_4 (Quantiz (None, 4, 540, 4)         20        \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 4, 2160)           0         \n",
            "_________________________________________________________________\n",
            "quantize_annotate_6 (Quantiz (None, 2)                 17304     \n",
            "_________________________________________________________________\n",
            "quantize_annotate_7 (Quantiz (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 17,327\n",
            "Trainable params: 17,327\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0km6-aGYVw9B"
      },
      "source": [
        "train_params = {\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 15,\n",
        "    \"verbose\": 1,\n",
        "    \"validation_data\": (X_val, y_val),\n",
        "}\n",
        "\n",
        "# history_cnn_lstm = cnn_lstm_model.fit(X_train, y_train, **train_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgAyOCs_i5Xg",
        "outputId": "aa86fbd2-05e4-40f9-c066-09bc86493c24"
      },
      "source": [
        "# quant_aware_model = tfmot.quantization.keras.quantize_apply(cnn_lstm_model)\n",
        "with quantize_scope(\n",
        "    {'DefaultQuantizeConfigCNNLSTM': DefaultQuantizeConfigCNNLSTM,\n",
        "     'DefaultQuantizeLSTMConfigCNNLSTM': DefaultQuantizeLSTMConfigCNNLSTM}):\n",
        "    cnn_lstm_quant_aware = tfmot.quantization.keras.quantize_apply(cnn_lstm_model)\n",
        "cnn_lstm_quant_aware.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "history_cnn_lstm = cnn_lstm_quant_aware.fit(X_train, y_train, **train_params)\n",
        "cnn_lstm_quant_aware.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "648/648 [==============================] - 61s 91ms/step - loss: 0.3033 - accuracy: 0.8764 - val_loss: 0.5271 - val_accuracy: 0.7746\n",
            "Epoch 2/15\n",
            "648/648 [==============================] - 58s 89ms/step - loss: 0.1833 - accuracy: 0.9466 - val_loss: 0.5304 - val_accuracy: 0.8142\n",
            "Epoch 3/15\n",
            "648/648 [==============================] - 57s 88ms/step - loss: 0.1462 - accuracy: 0.9585 - val_loss: 0.5475 - val_accuracy: 0.7998\n",
            "Epoch 4/15\n",
            "648/648 [==============================] - 57s 88ms/step - loss: 0.1265 - accuracy: 0.9641 - val_loss: 0.5813 - val_accuracy: 0.8053\n",
            "Epoch 5/15\n",
            "648/648 [==============================] - 58s 89ms/step - loss: 0.1133 - accuracy: 0.9682 - val_loss: 0.5692 - val_accuracy: 0.8097\n",
            "Epoch 6/15\n",
            "648/648 [==============================] - 58s 90ms/step - loss: 0.1014 - accuracy: 0.9713 - val_loss: 0.5757 - val_accuracy: 0.8173\n",
            "Epoch 7/15\n",
            "648/648 [==============================] - 57s 89ms/step - loss: 0.0917 - accuracy: 0.9738 - val_loss: 0.5766 - val_accuracy: 0.8014\n",
            "Epoch 8/15\n",
            "648/648 [==============================] - 57s 88ms/step - loss: 0.0834 - accuracy: 0.9763 - val_loss: 0.6049 - val_accuracy: 0.8179\n",
            "Epoch 9/15\n",
            "648/648 [==============================] - 57s 89ms/step - loss: 0.0777 - accuracy: 0.9777 - val_loss: 0.6084 - val_accuracy: 0.8052\n",
            "Epoch 10/15\n",
            "648/648 [==============================] - 58s 90ms/step - loss: 0.0718 - accuracy: 0.9793 - val_loss: 0.6158 - val_accuracy: 0.8260\n",
            "Epoch 11/15\n",
            "648/648 [==============================] - 58s 90ms/step - loss: 0.0673 - accuracy: 0.9802 - val_loss: 0.6486 - val_accuracy: 0.8121\n",
            "Epoch 12/15\n",
            "648/648 [==============================] - 58s 89ms/step - loss: 0.0637 - accuracy: 0.9814 - val_loss: 0.6391 - val_accuracy: 0.8284\n",
            "Epoch 13/15\n",
            "648/648 [==============================] - 57s 89ms/step - loss: 0.0595 - accuracy: 0.9829 - val_loss: 0.6303 - val_accuracy: 0.8211\n",
            "Epoch 14/15\n",
            "648/648 [==============================] - 57s 89ms/step - loss: 0.0561 - accuracy: 0.9837 - val_loss: 0.6500 - val_accuracy: 0.8346\n",
            "Epoch 15/15\n",
            "648/648 [==============================] - 57s 88ms/step - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.6578 - val_accuracy: 0.8316\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_layer_6 (QuantizeLa (None, 4, 540, 1)         3         \n",
            "_________________________________________________________________\n",
            "quant_time_distributed_2 (Qu (None, 4, 540, 8)         45        \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 4, 4320)           0         \n",
            "_________________________________________________________________\n",
            "quant_lstm_1 (QuantizeWrappe (None, 3)                 51893     \n",
            "_________________________________________________________________\n",
            "quant_output (QuantizeWrappe (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 51,950\n",
            "Trainable params: 51,932\n",
            "Non-trainable params: 18\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}